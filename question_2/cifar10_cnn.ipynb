{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c092d005",
   "metadata": {},
   "source": [
    "\n",
    "# CIFAR-10: Four-Layer CNN in TensorFlow — ReLU vs Tanh (Early Stop at 25% Training Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709971cb",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup & Imports\n",
    "If TensorFlow isn't installed, install it (e.g., `pip install tensorflow`). Then import the libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba117f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# If TensorFlow is not installed in your environment, uncomment the next line:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# !pip install -q tensorflow\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# If TensorFlow is not installed in your environment, uncomment the next line:\n",
    "# !pip install -q tensorflow\n",
    "\n",
    "import os, random, sys, time, math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c4dac",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Reproducibility & Global Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 100              # upper bound — we will stop early once accuracy >= 0.75\n",
    "TARGET_TRAIN_ACCURACY = 0.75  # 1 - 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ec69e",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load & Prepare CIFAR-10\n",
    "- CIFAR-10: 50k train / 10k test images (32×32×3), 10 classes.\n",
    "- Normalize images to [0,1].\n",
    "- Keep labels as integers and use SparseCategoricalCrossentropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8063645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Flatten label shape from (N,1) -> (N,)\n",
    "y_train = y_train.squeeze().astype(\"int32\")\n",
    "y_test = y_test.squeeze().astype(\"int32\")\n",
    "\n",
    "# Normalize to [0,1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "print(\"Train:\", x_train.shape, y_train.shape)\n",
    "print(\"Test :\", x_test.shape,  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653a240",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Input Pipeline (tf.data) + Augmentation\n",
    "- Shuffle, batch, prefetch for performance.\n",
    "- Optional Keras preprocessing layers for augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee52ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Validation split (10% of training)\n",
    "val_fraction = 0.1\n",
    "val_size = int(len(x_train) * val_fraction)\n",
    "x_val, y_val = x_train[:val_size], y_train[:val_size]\n",
    "x_train_sub, y_train_sub = x_train[val_size:], y_train[val_size:]\n",
    "\n",
    "# Datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_sub, y_train_sub)).shuffle(10_000, seed=SEED, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "test_ds  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# Simple augmentation (disable by setting do_augment=False)\n",
    "do_augment = True\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1),\n",
    "], name=\"augment\")\n",
    "\n",
    "print(train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502e3f9",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Model Builder: Four Conv Layers\n",
    "- Two conv blocks (Conv, Conv, MaxPool, Dropout) ×2 ⇒ **4 Conv layers total**.\n",
    "- Classifier head: Flatten → Dense(256) → Dropout → Dense(10, softmax).\n",
    "- Hidden layers use either **ReLU** or **Tanh** as requested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(activation: str = \"relu\", input_shape=(32, 32, 3), n_classes: int = 10) -> keras.Model:\n",
    "    # Build a four-convolutional-layer CNN for CIFAR-10.\n",
    "    inputs = keras.Input(shape=input_shape, name=\"images\")\n",
    "    x = inputs\n",
    "    if do_augment:\n",
    "        x = data_augmentation(x)\n",
    "\n",
    "    # Block A (2 conv layers)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=activation)(x)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=activation)(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "\n",
    "    # Block B (2 conv layers)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=activation)(x)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=activation)(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "\n",
    "    # Classifier head\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation=activation)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=f\"cnn_4conv_{activation}\")\n",
    "    return model\n",
    "\n",
    "# Quick check\n",
    "_ = build_cnn(\"relu\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda05b24",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Early Stop on Training Error ≤ 25%\n",
    "Stop when training accuracy ≥ 0.75 (i.e., error ≤ 25%). We check it at the end of each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1fc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopOnTrainingAccuracy(keras.callbacks.Callback):\n",
    "    def __init__(self, target_accuracy: float = 0.75):\n",
    "        super().__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        train_acc = logs.get(\"accuracy\") or logs.get(\"sparse_categorical_accuracy\")\n",
    "        if train_acc is not None and train_acc >= self.target_accuracy:\n",
    "            print(f\"\\nReached training accuracy {train_acc:.3f} ≥ {self.target_accuracy:.2f}. Stopping.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0e818",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Compile Helper\n",
    "Adam optimizer + SparseCategoricalCrossentropy + accuracy metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_model(model: keras.Model, lr: float = 1e-3):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ffa022",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Train Function\n",
    "Trains up to `MAX_EPOCHS` but stops early once training error ≤ 25%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(activation: str):\n",
    "    model = build_cnn(activation=activation)\n",
    "    compile_model(model)\n",
    "    callbacks = [StopOnTrainingAccuracy(target_accuracy=TARGET_TRAIN_ACCURACY)]\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc76b1",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Run Two Experiments: ReLU vs Tanh\n",
    "Only difference is the hidden-layer activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e448dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histories = {}\n",
    "\n",
    "print(\"\\n=== Training with ReLU activation ===\")\n",
    "model_relu, hist_relu = train_model(\"relu\")\n",
    "histories[\"relu\"] = hist_relu.history\n",
    "\n",
    "print(\"\\n=== Training with Tanh activation ===\")\n",
    "model_tanh, hist_tanh = train_model(\"tanh\")\n",
    "histories[\"tanh\"] = hist_tanh.history\n",
    "\n",
    "epochs_relu = len(histories[\"relu\"][\"loss\"])\n",
    "epochs_tanh = len(histories[\"tanh\"][\"loss\"])\n",
    "print(f\"ReLU stopped after {epochs_relu} epoch(s).\")\n",
    "print(f\"Tanh stopped after {epochs_tanh} epoch(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe2573",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Plots: Accuracy, Loss, and Training Error\n",
    "We overlay curves for ReLU and Tanh. The target line shows the 25% training error threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_series(ax, y, label):\n",
    "    ax.plot(np.arange(1, len(y)+1), y, label=label)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_series(plt.gca(), histories[\"relu\"][\"accuracy\"], \"ReLU — train acc\")\n",
    "plot_series(plt.gca(), histories[\"relu\"][\"val_accuracy\"], \"ReLU — val acc\")\n",
    "plot_series(plt.gca(), histories[\"tanh\"][\"accuracy\"], \"Tanh — train acc\")\n",
    "plot_series(plt.gca(), histories[\"tanh\"][\"val_accuracy\"], \"Tanh — val acc\")\n",
    "plt.axhline(TARGET_TRAIN_ACCURACY, linestyle=\"--\", linewidth=1, label=\"Target train acc (0.75)\")\n",
    "plt.title(\"Accuracy vs Epochs — ReLU vs Tanh\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Loss plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_series(plt.gca(), histories[\"relu\"][\"loss\"], \"ReLU — train loss\")\n",
    "plot_series(plt.gca(), histories[\"relu\"][\"val_loss\"], \"ReLU — val loss\")\n",
    "plot_series(plt.gca(), histories[\"tanh\"][\"loss\"], \"Tanh — train loss\")\n",
    "plot_series(plt.gca(), histories[\"tanh\"][\"val_loss\"], \"Tanh — val loss\")\n",
    "plt.title(\"Loss vs Epochs — ReLU vs Tanh\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Training error plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "relu_train_error = 1 - np.array(histories[\"relu\"][\"accuracy\"])\n",
    "tanh_train_error = 1 - np.array(histories[\"tanh\"][\"accuracy\"])\n",
    "plot_series(plt.gca(), relu_train_error, \"ReLU — train error\")\n",
    "plot_series(plt.gca(), tanh_train_error, \"Tanh — train error\")\n",
    "plt.axhline(0.25, linestyle=\"--\", linewidth=1, label=\"Target training error (0.25)\")\n",
    "plt.title(\"Training Error vs Epochs — ReLU vs Tanh\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff926a9",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Evaluate on Test Set\n",
    "Report final test accuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accs = {}\n",
    "loss, acc = model_relu.evaluate(test_ds, verbose=0)\n",
    "test_accs[\"relu\"] = acc\n",
    "loss, acc = model_tanh.evaluate(test_ds, verbose=0)\n",
    "test_accs[\"tanh\"] = acc\n",
    "\n",
    "print(\"Test accuracies:\", {k: float(v) for k, v in test_accs.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d7063",
   "metadata": {},
   "source": [
    "\n",
    "## 11) (Optional) Save Histories for Reporting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savez(\"histories_relu_tanh.npz\",\n",
    "         relu_acc=np.array(histories[\"relu\"][\"accuracy\"]),\n",
    "         relu_val_acc=np.array(histories[\"relu\"][\"val_accuracy\"]),\n",
    "         relu_loss=np.array(histories[\"relu\"][\"loss\"]),\n",
    "         relu_val_loss=np.array(histories[\"relu\"][\"val_loss\"]),\n",
    "         tanh_acc=np.array(histories[\"tanh\"][\"accuracy\"]),\n",
    "         tanh_val_acc=np.array(histories[\"tanh\"][\"val_accuracy\"]),\n",
    "         tanh_loss=np.array(histories[\"tanh\"][\"loss\"]),\n",
    "         tanh_val_loss=np.array(histories[\"tanh\"][\"val_loss\"]))\n",
    "print(\"Saved histories to histories_relu_tanh.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f987eba",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Notes\n",
    "- If training halts too soon, slightly lower `TARGET_TRAIN_ACCURACY` or reduce dropout/augmentation.\n",
    "- If you need higher capacity, increase filters or add BatchNorm after Conv2D layers.\n",
    "- A GPU is highly recommended.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar10_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
